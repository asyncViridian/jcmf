RNA Motifs Process Notes

===============================================================================

Regions of interest:
    chr1:149,844,498-149,849,024 -
        genome.ucsc.edu/cgi-bin/hgTracks?db=hg38&lastVirtModeType=default&lastVirtModeExtraState=&virtModeType=default&virtMode=0&nonVirtPosition=&position=chr1%3A149844498-149849024&hgsid=725072751_CDa4000ZfjAIuAaUC6vmqIGOqYhD
    chr5:140,072,857-140,108,630 -
        http://genome.ucsc.edu/cgi-bin/hgTracks?db=hg38&lastVirtModeType=default&lastVirtModeExtraState=&virtModeType=default&virtMode=0&nonVirtPosition=&position=chr5%3A140072857%2D140108630&hgsid=725074713_Dmj4c3zZn3vT3NSJGrQjYZVLzsbs
    chr12:62,602,752-62,622,213 +
        http://genome.ucsc.edu/cgi-bin/hgTracks?db=hg38&lastVirtModeType=default&lastVirtModeExtraState=&virtModeType=default&virtMode=0&nonVirtPosition=&position=chr12%3A62602752%2D62622213&hgsid=725072751_CDa4000ZfjAIuAaUC6vmqIGOqYhD
    chr2:218,255,319-218,257,366 +
        http://genome.ucsc.edu/cgi-bin/hgTracks?db=hg38&lastVirtModeType=default&lastVirtModeExtraState=&virtModeType=default&virtMode=0&nonVirtPosition=&position=chr2%3A218255319%2D218257366&hgsid=725074751_HUEhL9EESes7V284Qvcyo3fLpb4j

===============================================================================

Downloading the MAF files for alignment blocks using the UCSC browser:
01. Navigate to the UCSC genome browser. Any of the URLs in the "Regions of Interest" should work, or otherwise select the region of interest.
02. In the header bar, click Tools > Table Browser.
03. Configure: group:"Comparative Genomics", track:"Conservation", table:"Multiz Align (multiz100way)", region:position, output-format:MAF
04. Optionally, name the output file to save it directly to disk, or send output to some other web interface.

===============================================================================

Generating the merged alignment block sequences:
Run blockmerge, and pass the MAF file as "input filename".
    run blockmerge without arguments to get a description of the usage.
    This process creates a set of FASTA files, each of which is a set of input sequences consisting of multiple alignment blocks merged together. The sequences have their gap characters removed, and Ns are inserted for actual gaps between alignment blocks that must be bridged.

TODO: explanation of the functionality blockmerge provides

===============================================================================

Generating the predicted motifs and associated scores:
There are some scripts in the scripts directory, as well as a template source_mafs and workingdirectory to reflect the structure of the filesystem I used when running these scripts.
The executables:
    blockmerger.jar
        This jar executable generates the set of FASTA files representing all the "merged blocks" originally from the given MAF file.
        It has a relatively complex set of arguments to specify source, destination, and various parameters (see below)
    align.sh
        This script runs cmfinder with a set of arguments (listed within the script) on each of the FASTA files in the directory ./split relative to the current directory.
        It produces a set of folders containing the appropriate sorted output.
    score.sh
        Takes 1 argument: the path to newick phylogenetic tree
        This script scores each of the motifs (individual results and merged results both) that align.sh produces. It depends on the file structure that align.sh produces, and outputs several more directories. The actual scoring information is within ./scores, while extra produced files are moved to ./other
    listscores.sh
        This script generates some files that list all of the scores that score.sh calculated in order from least to greatest.
        TODO: update the script itself to not need an argument, instead using a relative file structure like the other 2 scripts
    trackgenerator.jar
        This jar executable generates a BED file track from a set of score files.
        It has a relatively complex set of arguments to specify which score dir, as well as output files (see below)
        TODO: update the arguments to specify the double and single track outputs?
    runAll.sh
        This script runs all of the previous executables in order, so that I don't have to do it manually. Requires a source MAF file and a directory to dump all of the split, results, score, etc. directories inside.

My workflow that I have used so far:
01. Download the MAF file
02. Create the working directory (i.e. a directory named "q_chr01_5block-10to3000-allspecies")
03. Run the runAll.sh script, like so (change out the parameters as appropriate, obviously):
    ./runAll.sh q_chr01_5block-10to3000-allspecies/ source_mafs/chr5.maf

===============================================================================

Generating the UCSC browser format track hub:
TODO

===============================================================================
===============================================================================
                         
  _  _ ___ __ _ __ _ ___ 
 | || (_-</ _` / _` / -_)
  \_,_/__/\__,_\__, \___|
               |___/     
===============================================================================
===============================================================================

TRACKGENERATOR.JAR

> java -jar trackgenerator.jar
Parsing failed. Reason: Missing required options: s, o
usage: TrackGenerator [options] -s <dirname> -o <filename>
 -o,--outFile <arg>   Output BED filename (including extension)
 -s,--srcDir <arg>    Input score files directory

===============================================================================

BLOCKMERGER.JAR

> java -jar blockmerger.jar
Parsing failed. Reason: Missing required options: s, o
usage: BlockMerger [options] -s <filename> -o <fileprefix>
 -base                           Use base-counting based merging (by
                                 default BlockMerger uses block-based
                                 merging).
    --gapThreshold <arg>         Maximum gap length between two source
                                 alignment blocks before they are
                                 determined unmergeable. Defaults to 300
    --maxOutputLength <arg>      Maximum length of the reference genome
                                 section in a resulting block that will
                                 still allow the resulting block to be
                                 output.Defaults to 5000
    --minNumSpecies <arg>        Minimum number of species that are
                                 mergeable to include in each result
                                 alignment block. Defaults to 5
    --minOutputLength <arg>      Minimum length of the reference genome
                                 section in a resulting block that will
                                 still allow the resulting block to be
                                 output.Defaults to 10
    --numBasesIncrement <arg>    Number of bases to increment between each
                                 output merged block (if using
                                 base-counting merging). Defaults to 50
    --numBasesPerOutput <arg>    Number of bases to include in each output
                                 block (if using base-counting merging).
                                 Defaults to 300
    --numBlocksPerOutput <arg>   Number of source blocks to include in
                                 each merged block (if using
                                 block-counting merging). Defaults to 5
 -o,--outName <arg>              Output FASTA files prefix
 -od,--outDir <arg>              Directory to write output files to.
                                 Defaults to current directory
 -s,--srcName <arg>              Input MAF file
 -sd,--srcDir <arg>              Directory to read input files from.
                                 Defaults to current directory

===============================================================================

CMFINDER04.PL

Options:
    -c <number>
     The maximum number of candidates in each sequence. Default 40. No bigger than 100.
    -m <number>
     The minimum length of candidates. Default 30
        NOTE THIS DOES NOT ACTUALLY EXIST
    -M <number>
     The maximum length of candidates. Default 100
        NOTE THIS DOES NOT ACTUALLY EXIST
    -f <number>
     The fraction of the sequences expected to contain the motif. Default 0.80
    -s1 <number>
     The max number of output single stem-loop motifs
    -s2 <number>
     The max number of output double stem-loop motifs
    -minspan1 <number>
     minimum span of a candidate sub-sequence in the heuristics to come up with an initial alignment for single-hairpin (h1) motifs
    -maxspan1 <number>
     like -minspan1, but maximum
    -minspan2 <number>
     like -minspan1, but for double-hairpin (h2) motifs
    -maxspan2 <number>
     like -minspan2, but maximal
    -combine
     Combine the output motifs. Default False
    -motifList <file>
     Produce a list of motifs generated, one motif per line.
    -o <number>
     Minimum overlap for combining motifs
    -n <number>
     Minimum number of sequences (weighted) for combining motifs
    -emSeq <file>
     Use the sequences in this fasta file for the expectation maximization step (i.e., the C executable cmfinder), but not for the earlier steps related to finding candidate motifs.  The reason for this distinction is that it is somewhat easier to add weighting to the cmfinder program, than the various canda, candf, cands and align programs.
    -likeold
     Behave as much as possible like the old CMfinder, e.g., passing --enone, --p56 and --degen-rand to cmfinder_inf11.  It's not possible to produce identical results to CMfinder 0.3, but these flags make it more similar.
    -fragmentary
     Pass --fragmentary for cmfinder
    -amaa
     Pass --amaa to cmfinder (align max align accuracy)
    -useOldCmfinder
     Run the old cmfinder executable, mainly to test whether we get different results because of this perl script, or the cmfinder_inf11 executable.
    -skipClustalw
     Do not run clustalw, like older installations lacking this program.
    -justGetCmfinderCommand
     Print the command to run for the cmfinder executable, with appropriate partial flags.  This can be used to realign an existing .sto file, for example.
    -copyCmfinderRunsFromLog <log-file>
     For debugging.  Reads a log file that contains cmfinder commands, and re-runs them with new CMfinder.
    -commaSepEmFlags x<flags>
     List of flags and arguments to pass to the EM-step cmfinder exe.  There's an 'x' at the beginning of the flags, so that perl doesn't interpret the flags as flags for it.  It's comma-separated where on the command line it would be space separated.  I think commas are safe, and mean that I don't have to worry about quoting stuff.  e.g., -commaSepEmFlags x--fragmentary,--filter-non-frag,--filter-non-frag-pad,10 would pass this to the cmfinder program: "--fragmentary --filter-non-frag --filter-non-frag-pad 10", i.e., just replace commas with spaces.
    -commaSepSummarizeFlags x<flags>
     Flags to pass to the --summarize command.  Same syntax as for --commaSepEmFlags
    -commaSepCandfFlags x<flags>
     Flags to pass to the candf command.  Same syntax as for --commaSepEmFlags
    -minCandScoreInFinal <number>
     Pass --min-cand-score-in-final <number> to cmfinder.  WARNING: there's a difference between using this flag (where even intermediate motifs will avoid these hits) and taking the low-scoring instances out of the final alignments (which might be combinations of motifs in which the sequence would have been lower-scoring).
    -filterNonFrag
     Pass --filter-non-frag to cmfinder
    -columnOnlyBasePairProbs
     Pass --column-only-base-pair-probs to cmfinder
    -saveTimer <file>
     create tab-delimited <file> containing timing stats on various sub-processes of this script.  the first tab-delimited field is the description of the sub-process, the second field is the total CPU time (user+sys) and the third field is the wall-clock time.  Sub-processes can occur in multiple lines if they are run multiple timers, so the caller should add them.  Due to my laziness, the time of the clustalw program (if used) is not counted.
    -cpu <num>
     use <num> CPUs for functionality that can use multi-CPUs (currently only the internal cmsearch commands in cmfinder04)
    -allCpus
     equivalent to -cpu X , where X is the number of available processors.
    -candsParallel
     run the two cands jobs in parallel, even if -cpu 1
    -outFileSuffix <string>
     add <string> to the output file names.  this is useful if you want to run the script in multiple ways in the same directory.
    -h
     Show this list
    -version
     Show package version

===============================================================================

CMFINDER04

Usage: cmfinder04 [options] <input-sto-file>
OR --summarize [options] <input-sto-file>

Basic options:
  -h        : show brief help on version and usage
  -a <f>    : input alignment file (.sto)
  -o <f>    : output alignment file (.sto)
  --version : show version

General cmfinder options:
  --degen-rand                    : randomize degenerate nucs like CMfinder 0.3
  --degen-keep                    : keep degenerate nucs and marginalize  [default]
  --fragmentary                   : allow truncated hits (independent of --degen-X, unlike pscore)
  --non-frag-avg-bppr             : ignore --fragmentary for calculating average base pair probs
  --wgsc                          : use GSC alg to weight sequences for redundancy
  --wpb                           : use PB alg to weight sequences for redundancy
  --ints-like-03                  : use ints for mutual info and partition func, like CMfinder 0.3 did
  --min-seq-weight <x>            : eliminate seqs from MSA whose TCM weight is below this value  [0.01]
  --no-elim-iden-seq              : don't eliminate identical sequences as candidate members
  --no-elim-iden-subseq           : don't eliminate identical sub-sequences of other sequences as candidate members
  --allow-untested-code           : run code that was never exercized in tests; don't abort to allow testing
  --min-cand-score-in-final <x>   : min cmsearch score to put a seq into the saved MSA.  [0]
  --bg-score-size <n>             : create this many randomized seqs for each input seq to get background score, below which candi                                                         dates are rejected  [0]
  --bg-score-evalue <x>           : try to get an EVD from --bg-score-size, and apply this E-value  [-1]
  --bg-score-scan-thresh <x>      : bitscore threshold (-T in cmsearch) to use for scanning --bg-score-size data.  [0]
  --bg-score-non-frag             : prevent --bg-score-size scans from using fragmentary modes -- force --nontrunc
  --filter-non-frag               : first run cmsearch with --notrunc, then run normal cmsearch only on the hits from --notrunc
  --filter-non-frag-pad <n>       : with --filter-non-frag, add this many nucs on 5' and 3' side of the non-frag hits  [20]
  --max-degen-per-hit <n>         : eliminate hits with this many degen nucs or more
  --max-degen-flanking-nucs <n>   : consider this many nucs beyond the 5' and 3' ends of each hit in counting degen nucs for --max                                                         -degen-per-hit
  --bad-distal-pairs-to-loop      : shift non-canon pairs in distal part of stems to the terminal loop
  --bad-distal-pairs-to-loop-only : just run the input msa (-a flag) thru --bad-distal-pairs-to-loop-test and save to output msa (                                                         -o flag)
  --min-term-loop-nucs <n>        : only with --bad-distal-pairs-to-loop, move even good base pairs into loop if there are fewer t                                                         han this many nucs in term loop.  But leave it alone if bp is truncated (with --fragmentary)
  --seed <n>                      : set random number generator's seed to <n>  [0]  (n>=0)
  --evalue <x>                    : use this E-value in ScanCand, in addition to a threshold (note: implies running internal cmcal                                                         ibrate, which will be very slow)
  --create-file-on-success <f>    : create this file, empty, upon successful completion of the program, for convenience elsewhere
  --save-after-first-M-step       : for debugging.  program exits after saving the file
  --save-in-progress              : for debugging, save MSA's as we processed
  --timer-append <f>              : append timing stats to tab-delimited file

options related to internal cmcalibrate/cmsearch:
  --tailn <n> : pass --gtailn or --ltailn as appropriate to cmcalibrate (default: accept cmcalibrate's default)
  --local     : local mode, i.e. don't pass -g to internal cmsearch
  --noF4F5    : set --noF4 and --noF5 (env def) to avoid glocal hmm
  --max       : pass --max to cmsearch (and skip calibrations in cmbuild)
  --amaa      : use maximal-alignment accuracy in cmsearch, i.e. don't pass --acyk
  --cpu <n>   : pass to internal cmsearch/cmcalibrate.  --cpu -1 means use all CPUs (default is --cpu 0, which is single-threaded)                                                           [0]  (n>=-1)

options related to internal cmbuild:
  --p56       : use the default prior from Infernal v0.56 through v1.0.2
  --prior <f> : read priors from file <f>
  --eent      : adjust eff seq # to achieve relative entropy target  [default]
  --enone     : no effective seq # weighting: just use nseq
  --EmN <n>   : number of sampled seqs to use for p7 local MSV calibration  [200]  (n>0)
  --EvN <n>   : number of sampled seqs to use for p7 local Vit calibration  [200]  (n>0)
  --ElfN <n>  : number of sampled seqs to use for p7 local Fwd calibration  [200]  (n>0)
  --EgfN <n>  : number of sampled seqs to use for p7 glocal Fwd calibration  [200]  (n>0)

options for --summarizea:
  --summarize              : perform functionality like 'summarize' program.  commandline has the .sto file
  --summarize-gsc          : use GSC alg weighting for --summarize
  --summarize-save-msa <f> : save MSA used by --summarize, for debugging modifications on loading
[jyzhou15@attu6 data]$ cmfinder04 -h
Usage: cmfinder04 [options] <input-sto-file>
OR --summarize [options] <input-sto-file>

Basic options:
  -h        : show brief help on version and usage
  -a <f>    : input alignment file (.sto)
  -o <f>    : output alignment file (.sto)
  --version : show version

General cmfinder options:
  --degen-rand                    : randomize degenerate nucs like CMfinder 0.3
  --degen-keep                    : keep degenerate nucs and marginalize  [default]
  --fragmentary                   : allow truncated hits (independent of --degen-X, unlike pscore)
  --non-frag-avg-bppr             : ignore --fragmentary for calculating average base pair probs
  --wgsc                          : use GSC alg to weight sequences for redundancy
  --wpb                           : use PB alg to weight sequences for redundancy
  --ints-like-03                  : use ints for mutual info and partition func, like CMfinder 0.3 did
  --min-seq-weight <x>            : eliminate seqs from MSA whose TCM weight is below this value  [0.01]
  --no-elim-iden-seq              : don't eliminate identical sequences as candidate members
  --no-elim-iden-subseq           : don't eliminate identical sub-sequences of other sequences as candidate members
  --allow-untested-code           : run code that was never exercized in tests; don't abort to allow testing
  --min-cand-score-in-final <x>   : min cmsearch score to put a seq into the saved MSA.  [0]
  --bg-score-size <n>             : create this many randomized seqs for each input seq to get background score, below which candidates are rejected  [0]
  --bg-score-evalue <x>           : try to get an EVD from --bg-score-size, and apply this E-value  [-1]
  --bg-score-scan-thresh <x>      : bitscore threshold (-T in cmsearch) to use for scanning --bg-score-size data.  [0]
  --bg-score-non-frag             : prevent --bg-score-size scans from using fragmentary modes -- force --nontrunc
  --filter-non-frag               : first run cmsearch with --notrunc, then run normal cmsearch only on the hits from --notrunc
  --filter-non-frag-pad <n>       : with --filter-non-frag, add this many nucs on 5' and 3' side of the non-frag hits  [20]
  --max-degen-per-hit <n>         : eliminate hits with this many degen nucs or more
  --max-degen-flanking-nucs <n>   : consider this many nucs beyond the 5' and 3' ends of each hit in counting degen nucs for --max-degen-per-hit
  --bad-distal-pairs-to-loop      : shift non-canon pairs in distal part of stems to the terminal loop
  --bad-distal-pairs-to-loop-only : just run the input msa (-a flag) thru --bad-distal-pairs-to-loop-test and save to output msa (-o flag)
  --min-term-loop-nucs <n>        : only with --bad-distal-pairs-to-loop, move even good base pairs into loop if there are fewer than this many nucs in term loop.  But leave it alone if   bp is truncated (with --fragmentary)
  --seed <n>                      : set random number generator's seed to <n>  [0]  (n>=0)
  --evalue <x>                    : use this E-value in ScanCand, in addition to a threshold (note: implies running internal cmcalibrate, which will be very slow)
  --create-file-on-success <f>    : create this file, empty, upon successful completion of the program, for convenience elsewhere
  --save-after-first-M-step       : for debugging.  program exits after saving the file
  --save-in-progress              : for debugging, save MSA's as we processed
  --timer-append <f>              : append timing stats to tab-delimited file

options related to internal cmcalibrate/cmsearch:
  --tailn <n> : pass --gtailn or --ltailn as appropriate to cmcalibrate (default: accept cmcalibrate's default)
  --local     : local mode, i.e. don't pass -g to internal cmsearch
  --noF4F5    : set --noF4 and --noF5 (env def) to avoid glocal hmm
  --max       : pass --max to cmsearch (and skip calibrations in cmbuild)
  --amaa      : use maximal-alignment accuracy in cmsearch, i.e. don't pass --acyk
  --cpu <n>   : pass to internal cmsearch/cmcalibrate.  --cpu -1 means use all CPUs (default is --cpu 0, which is single-threaded)  [0]  (n>=-1)

options related to internal cmbuild:
  --p56       : use the default prior from Infernal v0.56 through v1.0.2
  --prior <f> : read priors from file <f>
  --eent      : adjust eff seq # to achieve relative entropy target  [default]
  --enone     : no effective seq # weighting: just use nseq
  --EmN <n>   : number of sampled seqs to use for p7 local MSV calibration  [200]  (n>0)
  --EvN <n>   : number of sampled seqs to use for p7 local Vit calibration  [200]  (n>0)
  --ElfN <n>  : number of sampled seqs to use for p7 local Fwd calibration  [200]  (n>0)
  --EgfN <n>  : number of sampled seqs to use for p7 glocal Fwd calibration  [200]  (n>0)

options for --summarizea:
  --summarize              : perform functionality like 'summarize' program.  commandline has the .sto file
  --summarize-gsc          : use GSC alg weighting for --summarize
  --summarize-save-msa <f> : save MSA used by --summarize, for debugging modifications on loading
[jyzhou15@attu6 data]$ cmfinder04 -h
Usage: cmfinder04 [options] <input-sto-file>
OR --summarize [options] <input-sto-file>

Basic options:
  -h        : show brief help on version and usage
  -a <f>    : input alignment file (.sto)
  -o <f>    : output alignment file (.sto)
  --version : show version

General cmfinder options:
  --degen-rand                    : randomize degenerate nucs like CMfinder 0.3
  --degen-keep                    : keep degenerate nucs and marginalize  [default]
  --fragmentary                   : allow truncated hits (independent of --degen-X, unlike pscore)
  --non-frag-avg-bppr             : ignore --fragmentary for calculating average base pair probs
  --wgsc                          : use GSC alg to weight sequences for redundancy
  --wpb                           : use PB alg to weight sequences for redundancy
  --ints-like-03                  : use ints for mutual info and partition func, like CMfinder 0.3 did
  --min-seq-weight <x>            : eliminate seqs from MSA whose TCM weight is below this value  [0.01]
  --no-elim-iden-seq              : don't eliminate identical sequences as candidate members
  --no-elim-iden-subseq           : don't eliminate identical sub-sequences of other sequences as candidate members
  --allow-untested-code           : run code that was never exercized in tests; don't abort to allow testing
  --min-cand-score-in-final <x>   : min cmsearch score to put a seq into the saved MSA.  [0]
  --bg-score-size <n>             : create this many randomized seqs for each input seq to get background score, below which candidates are rejected  [0]
  --bg-score-evalue <x>           : try to get an EVD from --bg-score-size, and apply this E-value  [-1]
  --bg-score-scan-thresh <x>      : bitscore threshold (-T in cmsearch) to use for scanning --bg-score-size data.  [0]
  --bg-score-non-frag             : prevent --bg-score-size scans from using fragmentary modes -- force --nontrunc
  --filter-non-frag               : first run cmsearch with --notrunc, then run normal cmsearch only on the hits from --notrunc
  --filter-non-frag-pad <n>       : with --filter-non-frag, add this many nucs on 5' and 3' side of the non-frag hits  [20]
  --max-degen-per-hit <n>         : eliminate hits with this many degen nucs or more
  --max-degen-flanking-nucs <n>   : consider this many nucs beyond the 5' and 3' ends of each hit in counting degen nucs for --max-degen-per-hit
  --bad-distal-pairs-to-loop      : shift non-canon pairs in distal part of stems to the terminal loop
  --bad-distal-pairs-to-loop-only : just run the input msa (-a flag) thru --bad-distal-pairs-to-loop-test and save to output msa (-o flag)
  --min-term-loop-nucs <n>        : only with --bad-distal-pairs-to-loop, move even good base pairs into loop if there are fewer than this many nucs in term loop.  But leave it alone if bp is truncated (with --fragmentary)
  --seed <n>                      : set random number generator's seed to <n>  [0]  (n>=0)
  --evalue <x>                    : use this E-value in ScanCand, in addition to a threshold (note: implies running internal cmcalibrate, which will be very slow)
  --create-file-on-success <f>    : create this file, empty, upon successful completion of the program, for convenience elsewhere
  --save-after-first-M-step       : for debugging.  program exits after saving the file
  --save-in-progress              : for debugging, save MSA's as we processed
  --timer-append <f>              : append timing stats to tab-delimited file

options related to internal cmcalibrate/cmsearch:
  --tailn <n> : pass --gtailn or --ltailn as appropriate to cmcalibrate (default: accept cmcalibrate's default)
  --local     : local mode, i.e. don't pass -g to internal cmsearch
  --noF4F5    : set --noF4 and --noF5 (env def) to avoid glocal hmm
  --max       : pass --max to cmsearch (and skip calibrations in cmbuild)
  --amaa      : use maximal-alignment accuracy in cmsearch, i.e. don't pass --acyk
  --cpu <n>   : pass to internal cmsearch/cmcalibrate.  --cpu -1 means use all CPUs (default is --cpu 0, which is single-threaded)  [0]  (n>=-1)

options related to internal cmbuild:
  --p56       : use the default prior from Infernal v0.56 through v1.0.2
  --prior <f> : read priors from file <f>
  --eent      : adjust eff seq # to achieve relative entropy target  [default]
  --enone     : no effective seq # weighting: just use nseq
  --EmN <n>   : number of sampled seqs to use for p7 local MSV calibration  [200]  (n>0)
  --EvN <n>   : number of sampled seqs to use for p7 local Vit calibration  [200]  (n>0)
  --ElfN <n>  : number of sampled seqs to use for p7 local Fwd calibration  [200]  (n>0)
  --EgfN <n>  : number of sampled seqs to use for p7 glocal Fwd calibration  [200]  (n>0)

options for --summarizea:
  --summarize              : perform functionality like 'summarize' program.  commandline has the .sto file
  --summarize-gsc          : use GSC alg weighting for --summarize
  --summarize-save-msa <f> : save MSA used by --summarize, for debugging modifications on loading
